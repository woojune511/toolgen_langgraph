from langchain_openai import ChatOpenAI
import json
import re
from src.config import BASE_URL, API_KEY, MODEL_NAME
from src.reasoning.state import ReasoningState
from src.logger import get_logger
from src.utils.jupyter_sandbox import AgentSandbox

logger = get_logger(__name__)

llm = ChatOpenAI(
    base_url=BASE_URL,
    api_key=API_KEY,
    model=MODEL_NAME,
    temperature=0.7,
    max_retries=2,
    request_timeout=120,
    model_kwargs={
        "extra_body": {
            "reasoning": {"effort": "none"}
        }
    },
)


def cot_reasoner(state: ReasoningState):
    """
    Step 1: CoT ì¶”ë¡ 
    LLMì—ê²Œ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í’€ê²Œ í•œë‹¤.
    ì¬ì‹œë„ ì‹œì—ëŠ” ì´ì „ ì½”ë“œ ê²€ì¦ ê²°ê³¼ë¥¼ íŒíŠ¸ë¡œ ì œê³µí•œë‹¤.
    """
    problem = state["problem"]
    attempt = state.get("attempt", 0)

    logger.info(f"ğŸ§  CoT Reasoning (attempt {attempt + 1})...")

    if attempt == 0:
        # ì²« ì‹œë„: ìˆœìˆ˜ CoT
        prompt = f"""You are a math expert. Solve the following problem step by step.

## Problem:
{problem}

## Instructions:
1. Think through the problem carefully, step by step.
2. Show all your work and reasoning.
3. At the end, provide your final answer inside \\boxed{{}}.

## Solution:
"""
    else:
        # ì¬ì‹œë„: ì´ì „ ì½”ë“œ ê²°ê³¼ë¥¼ íŒíŠ¸ë¡œ ì œê³µ
        prev_code_result = state.get("code_result", "")
        prev_cot_answer = state.get("cot_answer", "")
        judge_reasoning = state.get("judge_reasoning", "")

        prompt = f"""You are a math expert. Your previous answer to this problem was INCORRECT.

## Problem:
{problem}

## Your Previous Answer: {prev_cot_answer}
## Code Verification Result: {prev_code_result}
## Why it was wrong: {judge_reasoning}

## Instructions:
1. Carefully reconsider the problem. Your previous approach had an error.
2. Use the code verification result as a hint â€” the code computed a different answer.
3. Think through the problem again step by step.
4. At the end, provide your corrected answer inside \\boxed{{}}.

## Corrected Solution:
"""

    response = llm.invoke(prompt).content
    logger.info(f"   CoT output length: {len(response)} chars")

    # boxed answer ì¶”ì¶œ (nested braces ì²˜ë¦¬)
    def extract_boxed(text):
        """\boxed{} ì•ˆì˜ ë‚´ìš©ì„ ì¶”ì¶œ. ì¤‘ì²© ì¤‘ê´„í˜¸ë„ ì²˜ë¦¬."""
        results = []
        for m in re.finditer(r'\\boxed\{', text):
            start = m.end()
            depth = 1
            i = start
            while i < len(text) and depth > 0:
                if text[i] == '{':
                    depth += 1
                elif text[i] == '}':
                    depth -= 1
                i += 1
            if depth == 0:
                results.append(text[start:i-1])
        return results

    boxed_match = extract_boxed(response)
    cot_answer = boxed_match[-1] if boxed_match else ""

    if not cot_answer:
        # fallback: ë§ˆì§€ë§‰ ì¤„ì—ì„œ ë‹µ ì¶”ì¶œ ì‹œë„
        lines = response.strip().split('\n')
        cot_answer = lines[-1].strip() if lines else ""

    logger.info(f"   CoT Answer: {cot_answer}")

    return {
        "cot_reasoning": response,
        "cot_answer": cot_answer,
        "attempt": attempt + 1,
    }


def code_verifier(state: ReasoningState, sandbox: AgentSandbox):
    """
    Step 2: ì½”ë“œ ê²€ì¦
    CoT ì¶”ë¡  ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” Python ì½”ë“œë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•œë‹¤.
    """
    problem = state["problem"]
    cot_reasoning = state["cot_reasoning"]
    cot_answer = state["cot_answer"]

    logger.info(f"ğŸ’» Generating verification code...")

    prompt = f"""You are a Python programmer. Your task is to write Python code that independently solves the following math problem to verify a given answer.

## Problem:
{problem}

## Proposed Answer (from reasoning): {cot_answer}

## Reasoning Process:
{cot_reasoning}

## Instructions:
1. Write Python code that solves this problem computationally.
2. The code should calculate the answer INDEPENDENTLY â€” do NOT just print the proposed answer.
3. Use libraries like `math`, `fractions`, `itertools`, `sympy` as needed.
4. At the end, print ONLY the final answer (nothing else).
5. If the answer is a fraction, use `fractions.Fraction` and print it in the form "a/b".
6. Keep the code simple and correct.

```python
# Your verification code here
```
"""

    response = llm.invoke(prompt).content

    # ì½”ë“œ ì¶”ì¶œ
    code_match = re.search(r'```python(.*?)```', response, re.DOTALL)
    if code_match:
        code = code_match.group(1).strip()
    else:
        # fallback: ì „ì²´ë¥¼ ì½”ë“œë¡œ ì·¨ê¸‰
        code = response.strip()

    logger.info(f"   Code length: {len(code)} chars")

    # ì½”ë“œ ì‹¤í–‰
    try:
        result = sandbox.run_code(code, mode="temporary")
        sandbox.cleanup_test_kernel()

        if result["stderr"]:
            logger.warning(f"   âš ï¸ Code Error: {result['stderr'][:200]}")
            return {
                "code": code,
                "code_result": "",
                "code_error": result["stderr"],
            }

        code_result = result["stdout"].strip()
        logger.info(f"   Code Result: {code_result}")

        return {
            "code": code,
            "code_result": code_result,
            "code_error": None,
        }

    except Exception as e:
        logger.error(f"   âŒ Code execution failed: {e}")
        return {
            "code": code,
            "code_result": "",
            "code_error": str(e),
        }


def judge(state: ReasoningState):
    """
    Step 3: Judge
    CoT ë‹µê³¼ ì½”ë“œ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìµœì¢… ë‹µì„ ê²°ì •í•œë‹¤.
    """
    cot_answer = state["cot_answer"]
    code_result = state.get("code_result", "")
    code_error = state.get("code_error")
    attempt = state["attempt"]

    logger.info(f"âš–ï¸ Judging (attempt {attempt})...")
    logger.info(f"   CoT: {cot_answer} | Code: {code_result} | Error: {code_error}")

    # ì½”ë“œ ì—ëŸ¬ê°€ ìˆìœ¼ë©´ CoT ë‹µì„ ì‹ ë¢°
    if code_error:
        logger.info(f"   Code had errors. Trusting CoT answer.")
        return {
            "verified": True,
            "final_answer": cot_answer,
            "judge_reasoning": f"Code execution failed ({code_error}). Using CoT answer.",
        }

    # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ì½”ë“œ ê²°ê³¼ ì±„íƒ
    if attempt >= 3:
        logger.info(f"   Max attempts reached. Using code result.")
        final = code_result if code_result else cot_answer
        return {
            "verified": True,
            "final_answer": final,
            "judge_reasoning": "Max attempts reached. Adopting code result.",
        }

    # LLMì—ê²Œ ë¹„êµ íŒë‹¨ ìš”ì²­
    prompt = f"""You are a math judge. Compare two answers to a math problem and determine if they are equivalent.

## CoT Answer: {cot_answer}
## Code Result: {code_result}

## Instructions:
- Answers may be in different formats (e.g., "13/3" vs "4.333..." vs "4 1/3" vs "\\frac{{13}}{{3}}").
- Determine if they represent the SAME mathematical value.
- Respond with EXACTLY one of:
  - "MATCH" â€” if the answers are mathematically equivalent
  - "MISMATCH: <brief explanation of the difference>"
"""

    response = llm.invoke(prompt).content.strip()
    logger.info(f"   Judge verdict: {response}")

    if response.startswith("MATCH"):
        return {
            "verified": True,
            "final_answer": cot_answer,
            "judge_reasoning": "CoT and code agree.",
        }
    else:
        # ë¶ˆì¼ì¹˜ â€” ì¬ì¶”ë¡  í•„ìš”
        mismatch_reason = response.replace("MISMATCH:", "").strip()
        logger.info(f"   âŒ Mismatch detected. Will retry reasoning.")
        return {
            "verified": False,
            "judge_reasoning": f"CoT={cot_answer}, Code={code_result}. {mismatch_reason}",
        }
