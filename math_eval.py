import os
import json
from src.agent.graph import build_graph
from src.logger import get_logger
import langchain
from langfuse.langchain import CallbackHandler
from src.config import RESULT_DIR
from src.utils.jupyter_sandbox import AgentSandbox

logger = get_logger("MainExecutor")

langchain.debug = True

def main():
    # 1. ì„¤ì •
    dataset_path = "/c1/geonju/toolgen/datasets/math/math_100.json"
    final_answer_dict = {}
    
    with open(dataset_path, 'r') as f:
        _json = json.load(f)['test']
    
    dataset = []
    for domain in _json:
        dataset += _json[domain]
    
    logger.info(f"Starting MATH 100 Evaluation")

    langfuse_handler = CallbackHandler()
    
    # 4. ì „ì²´ ë°ì´í„°ì…‹ ìˆœíšŒ (Question ë‹¨ìœ„ ì‹¤í–‰)
    total_tasks = len(dataset)
    logger.info(f"Total tasks to process: {total_tasks}")
        
    for i in range(total_tasks):
        # 4-1. ë¬¸ì œ ê°€ì ¸ì˜¤ê¸° (Flattened Question)
        task = dataset[i]
        question = task['question']
        answer = task['answer']
        domain = task['domain']
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ Processing Task [{i+1}/{total_tasks}]")
        logger.info(f"{'='*60}")

        with AgentSandbox() as sandbox:        

            app = build_graph(sandbox)

            # 4-2. ì´ˆê¸° ìƒíƒœ ì„¤ì • (State Injection)
            inputs = {
                "problem": question,          # Stuffed Prompt (Intro + Excel Path + Question)
                "work_dir": "./",     # (ì¤‘ìš”) ì—ì´ì „íŠ¸ê°€ ì‘ì—…í•  ì ˆëŒ€ ê²½ë¡œ
                "plan": [],
                "current_step_index": 0,
                "decision": "",
                "context_log": [],
                "variable_inventory": {},
                "tool_retrieved": [],
                "tool_generated": [],
                "feedback_history": [],
                "error": None
            }
            
            # 4-3. ê·¸ë˜í”„ ì‹¤í–‰
            try:
                # recursion_limit: ë³µì¡í•œ ë¬¸ì œì¼ìˆ˜ë¡ ë†’ê²Œ ì¡ì•„ì•¼ í•¨ (50~100)
                result = app.invoke(inputs, config={"recursion_limit": 100, "callbacks": [langfuse_handler]})

                final_answer = result.get("final_answer")
                if final_answer:
                    logger.info(f"âœ… Task {i} Completed.")
                    final_answer_dict[i] = {
                        "question": question,
                        "answer": answer,
                        "domain": domain,
                        "model_answer": final_answer
                    }
                    
                
                # (ì„ íƒ) ê²°ê³¼ í™•ì¸ ë¡œì§
                # Analysis: result['context_log'] ë§ˆì§€ë§‰ ë‚´ìš© í™•ì¸
                # Modeling: target_dirì— submission.csv ìƒê²¼ëŠ”ì§€ í™•ì¸
                
            except Exception as e:
                logger.error(f"âŒ Task {i} Failed: {e}")
                # ì—ëŸ¬ê°€ ë‚˜ë„ ë‹¤ìŒ ë¬¸ì œë¡œ ê³„ì† ì§„í–‰ (Continue)

        with open(os.path.join(RESULT_DIR, "math_100_result.json"), 'w') as f:
            json.dump(final_answer_dict, f, indent=4)


if __name__ == "__main__":
    main()
    # test_single()
    # run_test()